Task 6: K-Nearest Neighbors (KNN) Classification
ğŸ” Overview

This repository contains the solution for Task 6 of the Elevate AI & ML Internship. The objective of this task was to understand and implement the K-Nearest Neighbors (KNN) algorithm for classification, experiment with different values of K, and evaluate performance using accuracy and confusion matrices.

ğŸ“ Dataset

For this task, the Iris Dataset was used. It contains measurements of iris flowers from three species for classification purposes.

ğŸ› ï¸ Tools and Libraries Used

Python 3.x

Pandas

Scikit-learn

Matplotlib

âœ… Task Steps

1. Choose and Prepare Dataset
Loaded the dataset and normalized numerical features to improve model performance.

2. Train the KNN Model
Implemented using KNeighborsClassifier from scikit-learn.

Trained with default and tuned parameters.

3. Experiment with Different K Values
Tested multiple values of K to find the optimal neighbor count.

4. Model Evaluation
Evaluated accuracy on test data.

Generated a confusion matrix to check classification performance.

5. Visualize Decision Boundaries
Plotted decision regions to understand model behavior.

â–¶ï¸ How to Run

Install required libraries: pandas, scikit-learn, matplotlib.

Download the dataset from the provided link.

Run the script or Jupyter notebook to train, test, and visualize results.

ğŸ’¡ What I Learned

How KNN works by comparing feature similarity.

The effect of different K values on model accuracy.

How normalization improves KNN performance.

How to visualize and interpret decision boundaries.

ğŸ“‚ Submission

This repository is submitted as part of the Elevate AI & ML Internship - Task 6.
