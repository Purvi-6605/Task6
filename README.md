# Task6: K-Nearest Neighbors (KNN) Classification
**Overview**

This repository contains the solution for Task 6 of the Elevate AI & ML Internship. The objective of this task was to understand and implement the K-Nearest Neighbors (KNN) algorithm for classification, experiment with different values of K, and evaluate performance using accuracy and confusion matrices.

**Dataset**

For this task, the Iris Dataset was used. It contains measurements of iris flowers from three species for classification purposes.

**Tools and Libraries Used**
1.Python 3.x

2.Pandas

3.Scikit-learn

4.Matplotlib

**Task Steps**

1. Choose and Prepare Dataset:
Loaded the dataset and normalized numerical features to improve model performance.

2. Train the KNN Model:
Implemented using KNeighborsClassifier from scikit-learn.
Trained with default and tuned parameters.

3. Experiment with Different K Values:
Tested multiple values of K to find the optimal neighbor count.

4. Model Evaluation:
Evaluated accuracy on test data.
Generated a confusion matrix to check classification performance.

5. Visualize Decision Boundaries:
Plotted decision regions to understand model behavior.

**How to Run**

1.Install required libraries: pandas, scikit-learn, matplotlib.

2.Download the dataset from the provided link.

3.Run the script or Jupyter notebook to train, test, and visualize results.

**What I Learned**

1.How KNN works by comparing feature similarity.

2.The effect of different K values on model accuracy.

3.How normalization improves KNN performance.

How to visualize and interpret decision boundaries.

**Submission**

This repository is submitted as part of the Elevate AI & ML Internship - Task 6.
