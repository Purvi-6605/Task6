Task 6: K-Nearest Neighbors (KNN) Classification
🔍 Overview

This repository contains the solution for Task 6 of the Elevate AI & ML Internship. The objective of this task was to understand and implement the K-Nearest Neighbors (KNN) algorithm for classification, experiment with different values of K, and evaluate performance using accuracy and confusion matrices.

📁 Dataset

For this task, the Iris Dataset was used. It contains measurements of iris flowers from three species for classification purposes.

🛠️ Tools and Libraries Used

Python 3.x

Pandas

Scikit-learn

Matplotlib

✅ Task Steps

1. Choose and Prepare Dataset
Loaded the dataset and normalized numerical features to improve model performance.

2. Train the KNN Model
Implemented using KNeighborsClassifier from scikit-learn.

Trained with default and tuned parameters.

3. Experiment with Different K Values
Tested multiple values of K to find the optimal neighbor count.

4. Model Evaluation
Evaluated accuracy on test data.

Generated a confusion matrix to check classification performance.

5. Visualize Decision Boundaries
Plotted decision regions to understand model behavior.

▶️ How to Run

Install required libraries: pandas, scikit-learn, matplotlib.

Download the dataset from the provided link.

Run the script or Jupyter notebook to train, test, and visualize results.

💡 What I Learned

How KNN works by comparing feature similarity.

The effect of different K values on model accuracy.

How normalization improves KNN performance.

How to visualize and interpret decision boundaries.

📂 Submission

This repository is submitted as part of the Elevate AI & ML Internship - Task 6.
